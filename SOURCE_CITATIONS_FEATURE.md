# Source Citations with Confidence Scores - Complete Implementation

**Date:** January 29, 2026  
**Status:** âœ… Implemented and Tested  
**Testing:** 100% Pass Rate (11/11 validations)

---

## ğŸ¯ Overview

Every OWnet AI Agent response now automatically includes detailed source citations with confidence scores, showing exactly which data sources were used to generate the answer.

---

## âœ¨ What Was Added

### 1. **Automatic Source Citations**

Every response now ends with a comprehensive "Sources" section that lists:
- All data sources used (transcripts, emails, CRM data, etc.)
- Confidence/relevance scores for each source
- Preview of the content
- Metadata (dates, authors, values, etc.)

### 2. **Confidence Score Visualization**

Sources are ranked and color-coded by relevance:
- ğŸŸ¢ **90-100%**: Highly relevant
- ğŸŸ¡ **70-89%**: Moderately relevant  
- ğŸŸ  **Below 70%**: Contextually relevant

### 3. **Detailed Metadata**

Each source includes:
- **Title** - Name of the document/call/email
- **Date** - When it was created
- **Author** - Who created it (for emails)
- **Preview** - First 150 characters
- **Type-specific info** - Deal values, contact names, etc.

---

## ğŸ“Š Example Output

### User Query
```
"What did we discuss with Acme Corp?"
```

### Response (with citations)
```markdown
Based on your conversations with Acme Corp, here's what was discussed:

[... AI-generated response ...]

---

## ğŸ“š Sources

*This response was generated using 7 sources from your data.*

### ğŸ™ï¸ Call Transcripts

**1. Discovery Call with Acme Corp**
- ğŸŸ¢ Relevance: 95%
- ğŸ“… Date: 1/15/2026
- ğŸ“ Preview: "We discussed their infrastructure needs for the new office building..."
- ğŸ“ Section: 1

**2. Follow-up Call - Acme Technical Review**
- ğŸŸ¡ Relevance: 88%
- ğŸ“… Date: 1/20/2026
- ğŸ“ Preview: "Technical team asked about fiber capacity and redundancy options..."
- ğŸ“ Section: 2

### ğŸ“§ Emails

**1. Re: Proposal Questions**
- ğŸŸ¢ Relevance: 92%
- ğŸ“… Date: 1/18/2026
- ğŸ‘¤ From: john.smith@acmecorp.com
- ğŸ“ Preview: "Thanks for the detailed proposal. We have a few questions..."
- ğŸ‘¥ Contact: John Smith (Acme Corp)

**2. Pricing Clarification**
- ğŸŸ¡ Relevance: 85%
- ğŸ“… Date: 1/22/2026
- ğŸ‘¤ From: sarah.jones@acmecorp.com
- ğŸ“ Preview: "Could you break down the monthly recurring costs..."
- ğŸ‘¥ Contact: Sarah Jones (Acme Corp)

### ğŸ“‡ CRM Data

**1. Acme Corp - Office Infrastructure**
- ğŸŸ¢ Relevance: 100%
- ğŸ“… Date: 1/10/2026
- ğŸ“ Preview: "USD 250,000 - Proposal"
- ğŸ’° Value: USD 250,000
- ğŸ“Š Stage: Proposal

---

**Relevance Score Legend:**
- ğŸŸ¢ 90-100%: Highly relevant
- ğŸŸ¡ 70-89%: Moderately relevant
- ğŸŸ  Below 70%: Contextually relevant
```

---

## ğŸ”§ Technical Implementation

### Files Modified

#### 1. `/ow/lib/ai-agent-utils.ts`

**Added Interfaces:**
```typescript
export interface SourceCitation {
  id: string;
  type: 'transcript' | 'email' | 'calendar' | 'drive' | 'crm' | 'chat_history';
  title: string;
  date?: string;
  author?: string;
  confidence: number; // 0-1 similarity score
  preview: string; // First 150 chars
  metadata?: Record<string, unknown>;
}

export interface ContextSource {
  // ... existing fields ...
  sources?: SourceCitation[]; // NEW: Detailed source citations
}
```

**Added Function:**
```typescript
export function formatSourceCitations(contexts: ContextSource[]): string
```

**Enhanced Context Loading:**
- Transcript loading now captures similarity scores
- Email loading tracks sender and confidence
- CRM loading includes deal metadata
- All sources tracked with detailed citations

#### 2. `/ow/app/api/ownet/chat/route.ts`

**Added Import:**
```typescript
import { formatSourceCitations } from '@/lib/ai-agent-utils';
```

**Enhanced Streaming:**
```typescript
// After main response completes
const sourceCitations = formatSourceCitations(contexts);

if (sourceCitations) {
  sendData({
    type: 'content',
    text: sourceCitations
  });
  fullResponse += sourceCitations;
}
```

#### 3. `/ow/app/api/ownet/chat/route-enhanced.ts`

Same enhancements for consistency.

---

## ğŸ“ˆ How It Works

### 1. **Data Collection**

When loading context, the system now tracks:
```typescript
// For each source loaded
{
  id: 'unique-id',
  type: 'transcript',
  title: 'Call Title',
  date: '1/15/2026',
  confidence: 0.95, // From vector similarity
  preview: 'First 150 chars...',
  metadata: { /* type-specific data */ }
}
```

### 2. **Confidence Calculation**

**Vector Similarity (Transcripts & Emails):**
```sql
SELECT 1 - (embedding <=> $1::vector) as similarity
```
- Returns 0-1 score
- Higher = more relevant
- Based on semantic similarity

**Exact Match (CRM Data):**
```typescript
confidence: 1.0 // CRM data is exact match
```

### 3. **Formatting**

Sources are:
1. Collected from all contexts
2. Sorted by confidence (highest first)
3. Grouped by type
4. Formatted with emojis and metadata
5. Appended to response

---

## ğŸ¨ Source Type Formatting

### ğŸ™ï¸ Call Transcripts
```markdown
**1. Discovery Call with Acme Corp**
- ğŸŸ¢ Relevance: 95%
- ğŸ“… Date: 1/15/2026
- ğŸ“ Preview: "We discussed their infrastructure needs..."
- ğŸ“ Section: 1
```

### ğŸ“§ Emails
```markdown
**1. Re: Proposal Questions**
- ğŸŸ¢ Relevance: 92%
- ğŸ“… Date: 1/18/2026
- ğŸ‘¤ From: john.smith@acmecorp.com
- ğŸ“ Preview: "Thanks for the detailed proposal..."
- ğŸ‘¥ Contact: John Smith (Acme Corp)
```

### ğŸ“‡ CRM Data
```markdown
**1. Acme Corp - Office Infrastructure**
- ğŸŸ¢ Relevance: 100%
- ğŸ“… Date: 1/10/2026
- ğŸ“ Preview: "USD 250,000 - Proposal"
- ğŸ’° Value: USD 250,000
- ğŸ“Š Stage: Proposal
```

### ğŸ“„ Documents (when implemented)
```markdown
**1. Technical Proposal - Acme Corp**
- ğŸŸ¢ Relevance: 94%
- ğŸ“… Date: 1/12/2026
- ğŸ“ Preview: "Executive Summary: This proposal outlines..."
- ğŸ“ Location: Google Drive
```

---

## âœ… Testing Results

```
ğŸ§ª Test Suite: test-source-citations.ts

Total Validations: 11
âœ… Passed: 11 (100%)
âŒ Failed: 0 (0%)

Validated:
âœ… Sources header present
âœ… Transcript section formatting
âœ… Email section formatting
âœ… CRM section formatting
âœ… Confidence scores displayed
âœ… Emoji indicators working
âœ… Source titles shown
âœ… Authors/metadata included
âœ… Preview text included
âœ… Type-specific metadata
âœ… Legend included
```

---

## ğŸ¯ Benefits

### For Users

1. **Transparency** - See exactly what data informed the answer
2. **Trust** - Confidence scores show relevance
3. **Verification** - Can review original sources
4. **Context** - Understand where information came from

### For Debugging

1. **Quality Control** - Verify correct sources used
2. **Relevance Check** - See if similarity scores are appropriate
3. **Coverage** - Ensure all relevant data is being searched
4. **Troubleshooting** - Identify missing or incorrect sources

---

## ğŸ“Š Confidence Score Interpretation

### ğŸŸ¢ High Relevance (90-100%)
- **Meaning**: Highly relevant to the query
- **Action**: Primary sources for the response
- **Example**: Direct mention of query terms

### ğŸŸ¡ Moderate Relevance (70-89%)
- **Meaning**: Contextually relevant
- **Action**: Supporting information
- **Example**: Related topics or entities

### ğŸŸ  Lower Relevance (Below 70%)
- **Meaning**: Tangentially relevant
- **Action**: Background context
- **Example**: General information about topic

---

## ğŸ” Examples by Query Type

### Deal Information Query
```
Query: "What's the status of the Acme Corp deal?"

Sources:
- ğŸŸ¢ CRM: Acme Corp deal (100%)
- ğŸŸ¢ Transcript: Latest call with Acme (94%)
- ğŸŸ¡ Email: Proposal follow-up (87%)
- ğŸŸ¡ Email: Pricing questions (82%)
```

### Customer Activity Query
```
Query: "What activity have we had with Acme Corp this month?"

Sources:
- ğŸŸ¢ Transcript: Discovery call (96%)
- ğŸŸ¢ Transcript: Technical review (93%)
- ğŸŸ¢ Email: Proposal questions (91%)
- ğŸŸ¡ Email: Meeting confirmation (88%)
- ğŸŸ¡ Email: Pricing clarification (85%)
- ğŸŸ¢ CRM: Deal updates (100%)
```

### Technical Question Query
```
Query: "What technical requirements did Acme Corp mention?"

Sources:
- ğŸŸ¢ Transcript: Technical review call (98%)
- ğŸŸ¢ Email: Technical specs request (94%)
- ğŸŸ¡ Transcript: Discovery call (76%)
```

---

## ğŸš€ Future Enhancements

### Potential Improvements

1. **Click-to-View** - Make sources clickable to view full content
2. **Source Filtering** - Let users filter by source type
3. **Export Citations** - Download source list as PDF
4. **Relevance Tuning** - Adjust confidence thresholds
5. **Source Highlighting** - Show which parts of sources were used
6. **Citation Styles** - Support different formatting (APA, MLA, etc.)

### Analytics Opportunities

1. **Track Citation Usage** - Which sources are most valuable
2. **Confidence Trends** - Monitor average relevance scores
3. **Source Coverage** - Identify gaps in data
4. **User Engagement** - Do users review sources?

---

## ğŸ“ Configuration

### Confidence Thresholds

Currently hardcoded, but can be made configurable:

```typescript
// In formatSourceCitations()
const confidenceEmoji = 
  confidencePercent >= 90 ? 'ğŸŸ¢' : 
  confidencePercent >= 70 ? 'ğŸŸ¡' : 
  'ğŸŸ ';
```

### Preview Length

Currently 150 characters:

```typescript
preview: chunk.chunkText.substring(0, 150).trim() + '...'
```

Can be adjusted based on needs.

---

## ğŸ“ User Guide

### Reading Citations

1. **Check the emoji** - Quick visual indicator of relevance
2. **Read the preview** - Understand what the source contains
3. **Note the date** - Consider recency
4. **Review metadata** - Get additional context

### Understanding Confidence

- **High (ğŸŸ¢)**: Core sources, directly relevant
- **Medium (ğŸŸ¡)**: Supporting sources, contextually relevant
- **Lower (ğŸŸ )**: Background sources, tangentially relevant

### When to Review Sources

- **Critical decisions** - Verify high-stakes information
- **Unexpected answers** - Understand where info came from
- **Detailed analysis** - Deep dive into specifics
- **Quality check** - Ensure AI used correct data

---

## ğŸ› Known Limitations

1. **No source deduplication** - Same source may appear multiple times if multiple chunks used
2. **Preview truncation** - Long titles/previews may be cut off
3. **Metadata varies** - Different source types have different metadata
4. **No source ranking control** - Sorted by confidence only

---

## ğŸ“ Support

### Testing
```bash
cd /Users/dannydemichele/Opticwise/ow
npx tsx scripts/test-source-citations.ts
```

### Debugging

Check logs for:
```
[OWnet] Loaded context: {
  sources: ['transcript', 'email', 'crm'],
  totalTokens: 125000
}
```

Verify citations in response:
```
Look for "## ğŸ“š Sources" section at end of response
```

---

## ğŸ‰ Summary

**What Changed:**
- âœ… Every response now includes source citations
- âœ… Confidence scores show relevance (0-100%)
- âœ… Color-coded emojis for quick scanning
- âœ… Detailed metadata for each source
- âœ… Grouped by source type
- âœ… Includes legend for interpretation

**Impact:**
- **Transparency**: Users see exactly what data was used
- **Trust**: Confidence scores build credibility
- **Verification**: Easy to review original sources
- **Debugging**: Clear visibility into RAG pipeline

**Testing:**
- âœ… 100% test pass rate (11/11 validations)
- âœ… All source types formatted correctly
- âœ… Confidence scores displayed properly
- âœ… Metadata included appropriately

---

**Status:** âœ… **READY TO DEPLOY**

The source citations feature is fully implemented, tested, and ready for production use!
